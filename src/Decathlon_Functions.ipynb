{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "472e20ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up\n",
    "from bs4 import BeautifulSoup as bts\n",
    "import pandas as pd\n",
    "import requests\n",
    "import math #for rounding numbers\n",
    "from datetime import datetime, timedelta\n",
    "#from dateutil.relativedelta import relativedelta\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a3374fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for parsing the URLs\n",
    "def cookSoup(url): \n",
    "    result = requests.get(url, headers = {\"User-Agent\":\"Mozilla/5.0\"})\n",
    "    soup = bts(result.text, 'html.parser')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b18d45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for pagination - creating a list of urls from a category\n",
    "def pageCreation(soup, cat_url, country, cat):\n",
    "    url_list = [cat_url]\n",
    "    total_prod = soup.find(\"div\",{\"class\":\"plp-bar-info svelte-1uqvrhu\"}).find(\"span\", {\"class\":\"svelte-1uqvrhu\"}).text\n",
    "    #No of pages (rounding up all numbers) = math.ceil(int(total_prod)/40)\n",
    "    #Create list of urls within the cat\n",
    "    total_page = math.ceil(int(total_prod)/40)\n",
    "    for i in range(1, total_page):\n",
    "            page = f'{cat_url}?from={40 * i}&size=40'\n",
    "            url_list.append(page)\n",
    "    print (f'{country}_{cat}: There are {total_prod} products ({total_page} pages) in the category')\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "84ab078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get main data\n",
    "def getDecathlonData(country_url, url_list, country, cat):\n",
    "    prod_list = []\n",
    "    for url in url_list:\n",
    "        page_soup = cookSoup(url)\n",
    "        prod = page_soup.find_all(class_=\"dpb-holder loaded svelte-wmr4s2\")\n",
    "        for product in prod:\n",
    "            link = product.find(\"a\").attrs[\"href\"]\n",
    "            prod_cat = page_soup.find(\"h1\").text\n",
    "            prod_title = product.find(\"h2\",{\"class\":\"svelte-wmr4s2\"}).text\n",
    "            brand_name = product.find(\"strong\",{\"class\":\"svelte-wmr4s2\"}).text\n",
    "            prod_url = f'{country_url}{link}'\n",
    "            \n",
    "            #if all sku contains only 7 characters: prod_id = product.find(\"a\").attrs[\"href\"].partition(\"?mc=\")[2][0:7]\n",
    "            #taking sku's even in case of more than 7 character id's:\n",
    "            if link.partition(\"?mc=\")[2].rpartition('&')[0] == '':\n",
    "                prod_id = link.partition(\"?mc=\")[2]\n",
    "            else:\n",
    "                prod_id = link.partition(\"?mc=\")[2].rpartition('&')[0]\n",
    "\n",
    "            #product prices in case of product being discounted or not\n",
    "            if product.find(\"div\", {\"class\":\"prc__active-price svelte-1kkqb6z\"}) == None:\n",
    "                reg_price = product.find(\"span\", {\"class\":\"prc__previous\"}).text.replace('\\n','').replace('*','')\n",
    "                act_price = product.find(\"div\", {\"class\":\"prc__active-price svelte-1kkqb6z prc__active-price--sale\"}).text.replace('\\n','').replace('*','')\n",
    "            else:\n",
    "                reg_price = product.find(\"div\", {\"class\":\"prc__active-price svelte-1kkqb6z\"}).text.replace('\\n','').replace('*','')\n",
    "                act_price = None\n",
    "            \n",
    "            #product sticker (2 cases: present vs. abse)\n",
    "\n",
    "            if product.find(\"div\", {\"class\": \"sticker svelte-15lojui\"}) == None:\n",
    "                prod_sticker = None\n",
    "            else:\n",
    "                prod_sticker = product.find(\"div\", {\"class\": \"sticker svelte-15lojui\"}).text.replace('\\n','').replace('*','').replace(' ','')\n",
    "\n",
    "            prod_list.append({'title': prod_title,\n",
    "                             'sku': prod_id,\n",
    "                             'regular price': reg_price,\n",
    "                             'actual price' : act_price,\n",
    "                             'brand': brand_name,\n",
    "                             'url' : prod_url,\n",
    "                             'sticker' : prod_sticker,\n",
    "                             'category' : prod_cat})\n",
    "            \n",
    "    print(f'{country}_{cat}: {len(prod_list)} products have been scraped!')\n",
    "        \n",
    "    return prod_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f9f7f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save data into csv:\n",
    "def saveDecathlonData(country, cat, prod_list):\n",
    "    fetch_date=f'{datetime.date(datetime.today())}'\n",
    "    filename = f'{country}_{cat}_{len(prod_list)}_{fetch_date}.csv'.replace(\" \",\"_\")\n",
    "\n",
    "    with open(filename, \"w\", encoding='utf-8-sig', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file, delimiter = \",\")\n",
    "        writer.writerow([\"title\", \"sku\", \"reg_price\", \"act_price\", \"brand\", \"sticker\", \"category\", \"url\"])\n",
    "\n",
    "        for item in prod_list:\n",
    "            writer.writerow([item['title'], item['sku'], item['regular price'], item['actual price'], item['brand'], item['sticker'], item['category'], item['url']])\n",
    "    \n",
    "    return print(f'{country}_{cat}: Data has been saved in {filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3472edbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DE_Sportbekleidung Damen: There are 4226 products (106 pages) in the category\n",
      "DE_Sportbekleidung Damen: 4226 products have been scraped!\n",
      "DE_Sportbekleidung Damen: Data has been saved in DE_Sportbekleidung_Damen_4226_2022-04-07.csv\n"
     ]
    }
   ],
   "source": [
    "#DE - Woman sportwear\n",
    "cat_url = 'https://www.decathlon.de/browse/c0-damen/c1-sportbekleidung-damen/_/N-qjh2ro'\n",
    "country = 'DE'\n",
    "country_url = \"https://www.decathlon.de\"\n",
    "cat = 'Sportbekleidung Damen'\n",
    "\n",
    "soup = cookSoup(cat_url)\n",
    "url_list = pageCreation(soup, cat_url, country, cat)\n",
    "prod_list = getDecathlonData(country_url, url_list, country, cat)\n",
    "saveDecathlonData(country, cat, prod_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0904ce46",
   "metadata": {},
   "source": [
    "## To-do\n",
    "1. DONE: Remove the space AND * in price, SPACE in Sticker\n",
    "2. DONE: Saving URL as a list --> Scrape SKU in each URL OR: trying to extract SKU from the URL\n",
    "3. DONE: Pagination\n",
    "4. DONE: Saving as csv. with country_category as file name\n",
    "5. Wrap chunks of codes up into functions\n",
    "6. Auto translate category? https://medium.com/analytics-vidhya/how-to-translate-text-with-python-9d203139dcf5\n",
    "7. Make a list of different categories and countries\n",
    "8. Loop over cat & countries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
